{
    "componentChunkName": "component---src-templates-blog-post-js",
    "path": "/posts/e8f28250581f11ec88a32bd6d2ecba4b/",
    "result": {"data":{"allMysqlLists":{"edges":[{"node":{"title":"Group Backed by Top Companies Moves to Combat A.I. Bias in Hiring","status":1,"alt":"“This is not just adopting principles, but actually implementing something concrete,” said Kenneth Chenault, co-chairman of the group and former chief executive of American Express.","src":"https://static01.nyt.com/images/2021/12/08/business/08tech-antibias1/merlin_131249072_877b8e83-1e6d-40a4-b24c-c548c29e3de1-articleLarge.jpg?quality=75&auto=webp&disable=upscale","source":"nytime","menu":"business","local_src":"","load_img":"","img_url":"https://static01.nyt.com/images/2021/12/08/business/08tech-antibias1/merlin_131249072_877b8e83-1e6d-40a4-b24c-c548c29e3de1-videoLarge.jpg","href":"https://www.nytimes.com/2021/12/08/technology/group-backed-by-top-companies-moves-to-combat-ai-bias-in-hiring.html","description":"The organization has created a format for evaluating the technology, which is often used to screen job candidates.","country":"us","create_time":"2021-12-08T12:11:51.000Z","content":"[\"Artificial intelligence software is increasingly used by human resources departments to screen r\\u00e9sum\\u00e9s, conduct video interviews and assess a job seeker\\u2019s mental agility.\", \"Now, some of the largest corporations in America are joining an effort to prevent that technology from delivering biased results that could perpetuate or even worsen past discrimination.\", \"The Data & Trust Alliance, announced on Wednesday, has signed up major employers across a variety of industries, including CVS Health, Deloitte, General Motors, Humana, IBM, Mastercard, Meta (Facebook\\u2019s parent company), Nike and Walmart.\", \"The corporate group is not a lobbying organization or a think tank. Instead, it has developed an evaluation and scoring system for artificial intelligence software.\", \"The Data & Trust Alliance, tapping corporate and outside experts, has devised a 55-question evaluation, which covers 13 topics, and a scoring system. The goal is to detect and combat algorithmic bias.\", \"\\u201cThis is not just adopting principles, but actually implementing something concrete,\\u201d said Kenneth Chenault, co-chairman of the group and a former chief executive of American Express, which has agreed to adopt the anti-bias tool kit.\", \"The companies are responding to concerns, backed by an ample body of research, that A.I. programs can inadvertently produce biased results. Data is the fuel of modern A.I. software, so the data selected and how it is employed to make inferences are crucial.\", \"If the data used to train an algorithm is largely information about white men, the results will most likely be biased against minorities or women. Or if the data used to predict success at a company is based on who has done well at the company in the past, the result may well be an algorithmically reinforced version of past bias.\", \"Seemingly neutral data sets, when combined with others, can produce results that discriminate by race, gender or age. The group\\u2019s questionnaire, for example, asks about the use of such \\u201cproxy\\u201d data including cellphone type, sports affiliations and social club memberships.\", \"Governments around the world are moving to adopt rules and regulations. The European Union has proposed a regulatory framework for A.I. The White House is working on a \\u201cbill of rights\\u201d for A.I.\", \"In an advisory note to companies on the use of the technology, the Federal Trade Commission warned, \\u201cHold yourself accountable \\u2014 or be ready for the F.T.C. to do it for you.\\u201d\", \"The Data & Trust Alliance seeks to address the potential danger of powerful algorithms being used in work force decisions early rather than react after widespread harms are apparent, as Silicon Valley did on matters like privacy and the amplifying of misinformation.\", \"\\u201cWe\\u2019ve got to move past the era of \\u2018move fast and break things and figure it out later,\\u2019\\u201d said Mr. Chenault, who was on the Facebook board for two years, until 2020.\", \"Corporate America is pushing programs for a more diverse work force. Mr. Chenault, who is now chairman of the venture capital firm General Catalyst, is one of the most prominent African Americans in business.\", \"Told of the new initiative, Ashley Casovan, executive director of the Responsible AI Institute, a nonprofit organization developing a certification system for A.I. products, said the focused approach and big-company commitments were encouraging.\", \"\\u201cBut having the companies do it on their own is problematic,\\u201d said Ms. Casovan, who advises the Organization for Economic Cooperation and Development on A.I. issues. \\u201cWe think this ultimately needs to be done by an independent authority.\\u201d\", \"The corporate group grew out of conversations among business leaders who were recognizing that their companies, in nearly every industry, were \\u201cbecoming data and A.I. companies,\\u201d Mr. Chenault said. And that meant new opportunities, but also new risks.\", \"The group was brought together by Mr. Chenault and Samuel Palmisano, co-chairman of the alliance and former chief executive of IBM, starting in 2020, calling mainly on chief executives at big companies.\", \"They decided to focus on the use of technology to support work force decisions in hiring, promotion, training and compensation. Senior employees at their companies were assigned to execute the project.\", \"Internal surveys showed that their companies were adopting A.I.-guided software in human resources, but most of the technology was coming from suppliers. And the corporate users had little understanding of what data the software makers were using in their algorithmic models or how those models worked.\", \"To develop a solution, the corporate group brought in its own people in human resources, data analysis, legal and procurement, but also the software vendors and outside experts. The result is a bias detection, measurement and mitigation system for examining the data practices and design of human resources software.\", \"\\u201cEvery algorithm has human values embedded in it, and this gives us another lens to look at that,\\u201d said Nuala O\\u2019Connor, senior vice president for digital citizenship at Walmart. \\u201cThis is practical and operational.\\u201d\", \"The evaluation program has been developed and refined over the past year. The aim was to make it apply not only to major human resources software makers like Workday, Oracle and SAP, but also to the host of smaller companies that have sprung up in the fast-growing field called \\u201cwork tech.\\u201d\", \"Many of the questions in the anti-bias questionnaire focus on data, which is the raw material for A.I. models.\", \"\\u201cThe promise of this new era of data and A.I. is going to be lost if we don\\u2019t do this responsibly,\\u201d Mr. Chenault said.\"]","href_hash":"e8f28250581f11ec88a32bd6d2ecba4b"}}]}},"pageContext":{"slug":"e8f28250581f11ec88a32bd6d2ecba4b"}},
    "staticQueryHashes": ["3649515864","764694655"]}